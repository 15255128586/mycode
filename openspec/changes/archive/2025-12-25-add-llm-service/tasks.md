## 1. Implementation
- [x] 1.1 新增 LLM Service 基础工程与依赖
- [x] 1.2 实现 OpenAI 兼容的 /chat 接口（支持流式/非流式）
- [x] 1.3 接入 ModelScope API（环境变量配置 base_url、api_key、model）
- [x] 1.4 提供 Dockerfile 与 docker-compose 服务定义
- [x] 1.5 添加最小示例与使用说明
- [x] 1.6 添加基础测试（请求成功与错误处理）
